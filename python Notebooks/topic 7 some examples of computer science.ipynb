{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GC content: 50.00%\n"
     ]
    }
   ],
   "source": [
    "def calculate_gc_content(dna_sequence):\n",
    "    total_bases = len(dna_sequence)\n",
    "    gc_bases = dna_sequence.count('G') + dna_sequence.count('C')\n",
    "    gc_content = (gc_bases / total_bases) * 100\n",
    "    return gc_content\n",
    "\n",
    "# Example usage\n",
    "sequence = \"ATGCTGACCTGAACGATCGTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGC\"\n",
    "seq2 = \"GX\"\n",
    "gc_content = calculate_gc_content(seq2)\n",
    "print(\"GC content: {:.2f}%\".format(gc_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def detect_faces(image_path):\n",
    "    # Load the pre-trained face detection model\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform face detection\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the image with detected faces\n",
    "    cv2.imshow('Detected Faces', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "image_path = 'Food, Andy And Angela.jpg'\n",
    "detect_faces(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: [-y/5 - 18/25]\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, sympify, Eq, solve\n",
    "\n",
    "def solve_algebraic_equation(equation):\n",
    "    # Create symbols for the variables in the equation\n",
    "    variables = symbols('x')\n",
    "\n",
    "    # Parse the equation string into a SymPy expression\n",
    "    expr = sympify(equation)\n",
    "\n",
    "    # Create an equation object\n",
    "    eq = Eq(expr, 0)\n",
    "\n",
    "    # Solve the equation\n",
    "    solution = solve(eq, variables)\n",
    "\n",
    "    # Return the solution\n",
    "    return solution\n",
    "\n",
    "# Example usage\n",
    "equation = '5*x + 18/5 + y'\n",
    "solution = solve_algebraic_equation(equation)\n",
    "print(\"Solution:\", solution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def remove_background(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Create a mask initialized with zeros\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "\n",
    "    # Define the background and foreground model\n",
    "    bg_model = np.zeros((1, 65), np.float64)\n",
    "    fg_model = np.zeros((1, 65), np.float64)\n",
    "\n",
    "    # Define the rectangular region for initial foreground extraction\n",
    "    rectangle = (50, 50, image.shape[1] - 50, image.shape[0] - 50)\n",
    "\n",
    "    # Apply GrabCut algorithm to extract foreground\n",
    "    cv2.grabCut(image, mask, rectangle, bg_model, fg_model, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "    # Create a mask with probable foreground and definite foreground regions\n",
    "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "    # Apply the mask to the original image to remove the background\n",
    "    image_no_background = image * mask2[:, :, np.newaxis]\n",
    "\n",
    "    # Return the image with the background removed\n",
    "    return image_no_background\n",
    "\n",
    "# Example usage\n",
    "image_path = 'Food, Andy and Angela.jpg'\n",
    "result = remove_background(image_path)\n",
    "cv2.imshow('Image with Background Removed', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyautogui'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l_/j699flmx6dbc1vlb90jx_hyw0000gn/T/ipykernel_81609/937162627.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyautogui\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyautogui'"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "\n",
    "def send_message(message):\n",
    "    for _ in range(10):\n",
    "        pyautogui.typewrite(message)\n",
    "        pyautogui.press('enter')\n",
    "        time.sleep(1)  # Adjust the delay if needed\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'send_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l_/j699flmx6dbc1vlb90jx_hyw0000gn/T/ipykernel_81609/399436138.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello, its angela!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'send_message' is not defined"
     ]
    }
   ],
   "source": [
    "send_message(\"Hello, its angela!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3083804027.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/l_/j699flmx6dbc1vlb90jx_hyw0000gn/T/ipykernel_81609/3083804027.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    mport pyautogui\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mport pyautogui\n",
    "import time\n",
    "\n",
    "def send_message(message):\n",
    "    time.sleep(2)\n",
    "    for _ in range(10):\n",
    "        pyautogui.typewrite(message)\n",
    "        pyautogui.press('enter')\n",
    "        time.sleep(1)  # Adjust the delay if needed\n",
    "        \n",
    "        \n",
    "send_message(\"Hello, Andy and angela its python code sending your message!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar cascade for eye detection\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "# Open the video capture\n",
    "video_capture = cv2.VideoCapture(0)  # Change 0 to the index of your desired video source if multiple cameras are available\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video capture\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Convert the frame to grayscale for face and eye detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect eyes in the frame\n",
    "    eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw rectangles around the detected eyes\n",
    "    for (x, y, w, h) in eyes:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the video capture\n",
    "video_capture = cv2.VideoCapture(0)  # Change 0 to the index of your desired video source if multiple cameras are available\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video capture\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "NumPy boolean array indexing assignment cannot assign 3 input values to the 1586473 output values where the mask is true",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l_/j699flmx6dbc1vlb90jx_hyw0000gn/T/ipykernel_69174/21058386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Change the color of the skin regions to pink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mpink_skin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskin_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mpink_skin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpink_skin\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m147\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Pink color in BGR format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Combine the pink skin and original frame using inverse mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: NumPy boolean array indexing assignment cannot assign 3 input values to the 1586473 output values where the mask is true"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open the video capture\n",
    "video_capture = cv2.VideoCapture(0)  # Change 0 to the index of your desired video source if multiple cameras are available\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video capture\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Convert the frame to the HSV color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the range of skin color in HSV\n",
    "    lower_skin = np.array([0, 20, 70])\n",
    "    upper_skin = np.array([20, 255, 255])\n",
    "\n",
    "    # Create a mask for pixels within the skin color range\n",
    "    skin_mask = cv2.inRange(hsv_frame, lower_skin, upper_skin)\n",
    "\n",
    "    # Apply a Gaussian blur to the mask to reduce noise\n",
    "    skin_mask = cv2.GaussianBlur(skin_mask, (7, 7), 0)\n",
    "\n",
    "    # Create an inverse mask to exclude skin regions\n",
    "    inverse_mask = cv2.bitwise_not(skin_mask)\n",
    "\n",
    "    # Create a black background image\n",
    "    black_background = np.zeros(frame.shape, dtype=np.uint8)\n",
    "\n",
    "    # Change the color of the skin regions to pink\n",
    "    pink_skin = cv2.bitwise_and(frame, frame, mask=skin_mask)\n",
    "    pink_skin[pink_skin != 0] = [147, 20, 255]  # Pink color in BGR format\n",
    "\n",
    "    # Combine the pink skin and original frame using inverse mask\n",
    "    output_frame = cv2.bitwise_and(frame, inverse_mask) + cv2.bitwise_and(pink_skin, skin_mask)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', output_frame)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/core/src/arithm.cpp:214: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function 'binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l_/j699flmx6dbc1vlb90jx_hyw0000gn/T/ipykernel_69174/1183963302.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Combine the pink skin and original frame using inverse mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0moutput_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpink_skin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskin_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Display the resulting frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/core/src/arithm.cpp:214: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function 'binary_op'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open the video capture\n",
    "video_capture = cv2.VideoCapture(0)  # Change 0 to the index of your desired video source if multiple cameras are available\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video capture\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Convert the frame to the HSV color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the range of skin color in HSV\n",
    "    lower_skin = np.array([0, 20, 70])\n",
    "    upper_skin = np.array([20, 255, 255])\n",
    "\n",
    "    # Create a mask for pixels within the skin color range\n",
    "    skin_mask = cv2.inRange(hsv_frame, lower_skin, upper_skin)\n",
    "\n",
    "    # Apply a Gaussian blur to the mask to reduce noise\n",
    "    skin_mask = cv2.GaussianBlur(skin_mask, (7, 7), 0)\n",
    "\n",
    "    # Create an inverse mask to exclude skin regions\n",
    "    inverse_mask = cv2.bitwise_not(skin_mask)\n",
    "\n",
    "    # Change the color of the skin regions to pink\n",
    "    pink_skin = cv2.bitwise_and(frame, frame, mask=skin_mask)\n",
    "    pink_color = np.zeros_like(pink_skin)\n",
    "    pink_color[:] = (147, 20, 255)  # Pink color in BGR format\n",
    "    pink_skin = cv2.addWeighted(pink_skin, 1, pink_color, 1, 0)\n",
    "\n",
    "    # Combine the pink skin and original frame using inverse mask\n",
    "    output_frame = cv2.bitwise_and(frame, inverse_mask) + cv2.bitwise_and(pink_skin, skin_mask)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', output_frame)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200]\n"
     ]
    }
   ],
   "source": [
    "# make prime number lis if you hae a lisf of 1 to 200\n",
    "lst = list(range(1,201))\n",
    "# from the lst you have to make list of evennumbers\n",
    "# even can be collected using each%2--0,,,, and you can append each\n",
    "five = []\n",
    "primes = []\n",
    "for each in lst:\n",
    "    if each%2==0:\n",
    "        even.append(each)\n",
    "    # separate odd numbers in odd variable just like you did for even\n",
    "    if each%2!=0:\n",
    "        odd.append(each)\n",
    "    if each%5==0:\n",
    "        five.append(each)\n",
    "\n",
    "\n",
    "print(five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how to find prime numbers\n",
    "### you can use,,,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
